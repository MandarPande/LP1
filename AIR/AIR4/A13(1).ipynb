{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement syntax analysis for the assertive English statements. The stages to be executed are, \n",
    "<ul>\n",
    "    <li>Sentence segmentation.\n",
    "    <li>Word tokenization\n",
    "    <li>Part-of-speech/morpho syntactic tagging.\n",
    "    <li>Syntactic parsing (Use any of the parser like Stanford)\n",
    "</ul>        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=\"This is sentence1. This is sent2. This is sent3. Another sentence. Last one\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is sentence1.', 'This is sent2.', 'This is sent3.', 'Another sentence.', 'Last one']\n"
     ]
    }
   ],
   "source": [
    "#1.Sentence segmentation\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sentences=sent_tokenize(sample)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['This', 'is', 'sentence1', '.'], ['This', 'is', 'sent2', '.'], ['This', 'is', 'sent3', '.'], ['Another', 'sentence', '.'], ['Last', 'one']]\n"
     ]
    }
   ],
   "source": [
    "#2.Word tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "words=[]\n",
    "for sent in sentences:\n",
    "    words_sent=word_tokenize(sent)\n",
    "    words.append(words_sent)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('This', 'DT'), ('is', 'VBZ'), ('sentence1', 'JJ'), ('.', '.')], [('This', 'DT'), ('is', 'VBZ'), ('sent2', 'JJ'), ('.', '.')], [('This', 'DT'), ('is', 'VBZ'), ('sent3', 'JJ'), ('.', '.')], [('Another', 'DT'), ('sentence', 'NN'), ('.', '.')], [('Last', 'JJ'), ('one', 'CD')]]\n"
     ]
    }
   ],
   "source": [
    "#3.POS tagging\n",
    "from nltk import pos_tag\n",
    "pos_list=[]\n",
    "for word in words:\n",
    "    pos_sent=pos_tag(word)\n",
    "    pos_list.append(pos_sent)\n",
    "\n",
    "print(pos_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: The StanfordParser will be deprecated\n",
      "Please use \u001b[91mnltk.parse.corenlp.CoreNLPParser\u001b[0m instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT (S (NP (DT This)) (VP (VBZ is) (ADJP (JJ sentence1))) (. .)))\n",
      "(ROOT (S (NP (DT This)) (VP (VBZ is) (ADJP (JJ sent2))) (. .)))\n",
      "(ROOT (S (NP (DT This)) (VP (VBZ is) (ADJP (JJ sent3))) (. .)))\n",
      "(ROOT (NP (DT Another) (NN sentence) (. .)))\n",
      "(ROOT (NP (JJ Last) (NN one)))\n"
     ]
    }
   ],
   "source": [
    "#4.Syntactic parsing\n",
    "'''\n",
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "parser=CoreNLPParser()\n",
    "next(parser.raw_parse(\"What is the longest river in the world?\"))\n",
    "'''\n",
    "\n",
    "from nltk.parse.stanford import StanfordParser\n",
    "eng_parser=StanfordParser('stanford-parser-full-2014-08-27/stanford-parser-full-2014-08-27/stanford-parser.jar','stanford-parser-full-2014-08-27/stanford-parser-full-2014-08-27/stanford-parser-3.4.1-models.jar')\n",
    "\n",
    "list_sent=[]\n",
    "for sent in sentences:\n",
    "    list_sent.append(eng_parser.raw_parse(sent))\n",
    "for sent in list_sent:\n",
    "    for i in iter(sent):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x25f2d67d400>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_parser.raw_parse_sents((\"This is sent1\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
